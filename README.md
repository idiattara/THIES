# ğŸ“˜ Introduction Ã  Apache Airflow

## ğŸ¯ Objectifs du cours
Ce document vise Ã  vous faire dÃ©couvrir Apache Airflow, un outil dâ€™orchestration de workflows Ã©crit en Python. Ã€ la fin de cette lecture, vous serez capable de :

- Comprendre ce quâ€™est Apache Airflow et Ã  quoi il sert
- Identifier les concepts clÃ©s (DAG, tÃ¢che, opÃ©rateurâ€¦)
- CrÃ©er un premier DAG simple
- Comprendre comment Airflow planifie et exÃ©cute des workflows

---

## ğŸ“Œ 1. Quâ€™est-ce quâ€™Apache Airflow ?

Apache Airflow est un outil **open-source** dÃ©veloppÃ© par Airbnb en 2014, devenu un projet officiel de la **Fondation Apache**.

Il permet de :
- Concevoir, planifier, et surveiller des **workflows** (pipelines de donnÃ©es)
- Orchestrer des tÃ¢ches sous forme de **graphes dirigÃ©s acycliques (DAGs)**
- ExÃ©cuter des tÃ¢ches de maniÃ¨re planifiÃ©e, conditionnelle ou parallÃ¨le

> âœ¨ Airflow est Ã©crit en **Python**, ce qui permet de dÃ©crire ses workflows sous forme de code.

---

## ğŸ§© 2. Concepts clÃ©s

### 2.1 DAG (Directed Acyclic Graph)
Un **DAG** est un ensemble de tÃ¢ches liÃ©es entre elles, reprÃ©sentÃ©es comme un graphe sans cycle. Il dÃ©finit **lâ€™ordre dâ€™exÃ©cution** des tÃ¢ches.

### 2.2 Task (TÃ¢che)
Une tÃ¢che est une unitÃ© de travail (exÃ©cuter un script, une commande, une API, etc.).

### 2.3 Operator (OpÃ©rateur)
Un opÃ©rateur reprÃ©sente **le type de tÃ¢che** :
- `PythonOperator` : fonction Python
- `BashOperator` : commande shell
- `EmailOperator`, `PostgresOperator`, etc.

### 2.4 Scheduler
Câ€™est le **planificateur** qui exÃ©cute les DAGs selon un calendrier dÃ©fini (`@daily`, `@hourly`, etc.).

### 2.5 Executor
Câ€™est lâ€™**exÃ©cuteur** des tÃ¢ches (localement, en parallÃ¨le, via Celery, etc.).

---

## ğŸ—ï¸ 3. Exemple de DAG simple

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG(
    dag_id="mon_premier_dag",
    start_date=datetime(2023, 1, 1),
    schedule_interval="@daily",
    catchup=False
) as dag:

    t1 = BashOperator(
        task_id="tache_1",
        bash_command="echo 'Bonjour depuis Airflow!'"
    )

    t2 = BashOperator(
        task_id="tache_2",
        bash_command="echo 'DeuxiÃ¨me tÃ¢che.'"
    )

    t1 >> t2  # t1 sâ€™exÃ©cute avant t2
